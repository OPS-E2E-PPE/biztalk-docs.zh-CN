---
title: Hyper V 上的系统资源成本 |Microsoft Docs
ms.custom: ''
ms.date: 06/08/2017
ms.prod: biztalk-server
ms.reviewer: ''
ms.suite: ''
ms.tgt_pltfrm: ''
ms.topic: article
ms.assetid: 9f25a76c-1c41-41c0-b28d-d7473dbe1cd1
caps.latest.revision: 8
author: MandiOhlinger
ms.author: mandia
manager: anneta
ms.openlocfilehash: 768b34b6b1a51768f1c0070c961749e1975015f9
ms.sourcegitcommit: 53b16fe6c1b1707ecf233dbd05f780653eb19419
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 11/01/2018
ms.locfileid: "50753053"
---
# <a name="system-resource-costs-on-hyper-v"></a><span data-ttu-id="d900c-102">Hyper V 上的系统资源成本</span><span class="sxs-lookup"><span data-stu-id="d900c-102">System Resource Costs on Hyper-V</span></span>
## <a name="system-resource-costs-associated-with-running-a-guest-operating-system-on-hyper-v"></a><span data-ttu-id="d900c-103">与 HYPER-V 上运行来宾操作系统相关联的系统资源成本</span><span class="sxs-lookup"><span data-stu-id="d900c-103">System Resource Costs Associated with Running a Guest Operating System on Hyper-V</span></span>  
 <span data-ttu-id="d900c-104">与任何服务器虚拟化软件一样，没有一定的开销与运行支持的 HYPER-V 上运行的来宾操作系统所需的虚拟化代码相关联。</span><span class="sxs-lookup"><span data-stu-id="d900c-104">As with any server virtualization software, there is a certain amount of overhead associated with running the virtualization code required to support guest operating systems running on Hyper-V.</span></span> <span data-ttu-id="d900c-105">以下列表汇总了当 HYPER-V 虚拟机上运行的来宾操作系统与特定资源相关的开销：</span><span class="sxs-lookup"><span data-stu-id="d900c-105">The following list summarizes the overhead associated with specific resources when running guest operating systems on Hyper-V virtual machines:</span></span>  
  
### <a name="cpu-overhead"></a><span data-ttu-id="d900c-106">CPU 开销</span><span class="sxs-lookup"><span data-stu-id="d900c-106">CPU Overhead</span></span>  
 <span data-ttu-id="d900c-107">CPU 与 HYPER-V 虚拟机中运行来宾操作系统的系统开销关联找到 9 和 12%之间的范围。</span><span class="sxs-lookup"><span data-stu-id="d900c-107">The CPU overhead associated with running a guest operating system in a Hyper-V virtual machine was found to range between 9 and 12%.</span></span>  <span data-ttu-id="d900c-108">例如，通常运行的 HYPER-V 虚拟机上的来宾操作系统必须在物理硬件上运行等效的操作系统可用的 CPU 资源的可用 88 91%。</span><span class="sxs-lookup"><span data-stu-id="d900c-108">For example, a guest operating system running on a Hyper-V virtual machine typically had available 88-91% of the CPU resources available to an equivalent operating system running on physical hardware.</span></span>  
  
### <a name="memory-overhead"></a><span data-ttu-id="d900c-109">内存开销</span><span class="sxs-lookup"><span data-stu-id="d900c-109">Memory Overhead</span></span>  
 <span data-ttu-id="d900c-110">对于 HYPER-V 主机计算机，与 HYPER-V 虚拟机上运行来宾操作系统相关的内存开销观察到为大约 300 MB 的虚拟机监控程序，加上 32 MB 的第一个 GB 的 RAM 分配给每个虚拟机，再加上另一台 8 MB对于每个其他 GB 的 RAM 分配给每个虚拟机。</span><span class="sxs-lookup"><span data-stu-id="d900c-110">For the Hyper-V host computer, the memory cost associated with running a guest operating system on a Hyper-V virtual machine was observed to be approximately 300 MB for the hypervisor, plus 32 MB for the first GB of RAM allocated to each virtual machine, plus another 8 MB for every additional GB of RAM allocated to each virtual machine.</span></span> <span data-ttu-id="d900c-111">有关分配内存的 HYPER-V 虚拟机上运行的来宾操作系统的详细信息，请参阅中的"优化内存性能"一节[清单： 优化 HYPER-V 上的性能](~/technical-guides/checklist-optimizing-performance-on-hyper-v.md)。</span><span class="sxs-lookup"><span data-stu-id="d900c-111">For more information about allocating memory to guest operating systems running on a Hyper-V virtual machine, see the “Optimizing Memory Performance” section in [Checklist: Optimizing Performance on Hyper-V](~/technical-guides/checklist-optimizing-performance-on-hyper-v.md).</span></span>  
  
### <a name="network-overhead"></a><span data-ttu-id="d900c-112">网络开销</span><span class="sxs-lookup"><span data-stu-id="d900c-112">Network Overhead</span></span>  
 <span data-ttu-id="d900c-113">直接观察到的 HYPER-V 虚拟机中运行来宾操作系统是由引起了网络延迟为不超过 1 毫秒和来宾操作系统通常维护的网络输出队列长度小于 1。</span><span class="sxs-lookup"><span data-stu-id="d900c-113">Network latency directly attributable to running a guest operating system in a Hyper-V virtual machine was observed to be less than 1 ms and the guest operating system typically maintained a network output queue length of less than one.</span></span> <span data-ttu-id="d900c-114">有关测量网络输出队列长度的详细信息，请参阅中的"测量网络性能"一节[清单： 度量 HYPER-V 上的性能](../technical-guides/checklist-measuring-performance-on-hyper-v.md)。</span><span class="sxs-lookup"><span data-stu-id="d900c-114">For more information about measuring the network output queue length, see the “Measuring Network Performance” section in [Checklist: Measuring Performance on Hyper-V](../technical-guides/checklist-measuring-performance-on-hyper-v.md).</span></span>  
  
### <a name="disk-overhead"></a><span data-ttu-id="d900c-115">磁盘开销</span><span class="sxs-lookup"><span data-stu-id="d900c-115">Disk Overhead</span></span>  
 <span data-ttu-id="d900c-116">当在 HYPER-V 中使用的传递磁盘功能，磁盘 I/O 开销与在 HYPER-V 虚拟机中运行来宾操作系统找到介于 6 和 8%。</span><span class="sxs-lookup"><span data-stu-id="d900c-116">When using the passthrough disk feature in Hyper-V, disk I/O overhead associated with running a guest operating system in a Hyper-V virtual machine was found to range between 6 and 8 %.</span></span> <span data-ttu-id="d900c-117">例如，通常运行的 HYPER-V 上的来宾操作系统必须可用 92 94%的磁盘 I/O 供等效操作系统由开放源磁盘性能基准测试工具 IOMeter 的物理硬件上运行。</span><span class="sxs-lookup"><span data-stu-id="d900c-117">For example, a guest operating system running on Hyper-V typically had available 92-94% of the disk I/O available to an equivalent operating system running on physical hardware as measured by the open source disk performance benchmarking tool IOMeter.</span></span>  
  
 <span data-ttu-id="d900c-118">有关测量磁盘延迟的 HYPER-V 主机或来宾操作系统上使用性能监视器的信息，请参阅中的"衡量磁盘 I/O 性能"一节[清单： 度量 HYPER-V 上的性能](../technical-guides/checklist-measuring-performance-on-hyper-v.md)。</span><span class="sxs-lookup"><span data-stu-id="d900c-118">For information about measuring disk latency on a Hyper-V host or guest operating system using Performance Monitor, see the “Measuring Disk I/O Performance” section in [Checklist: Measuring Performance on Hyper-V](../technical-guides/checklist-measuring-performance-on-hyper-v.md).</span></span>  
  
 <span data-ttu-id="d900c-119">本部分的其余部分在 BizTalk Server 上的磁盘性能提供了背景信息，描述测试配置参数使用，并提供获得的测试结果的摘要。</span><span class="sxs-lookup"><span data-stu-id="d900c-119">The remainder of this section provides background information on BizTalk Server disk performance, describes the test configuration parameters used, and provides a summary of test results obtained.</span></span>  
  
#### <a name="disk-performance-when-running-a-biztalk-server-solution-on-hyper-v"></a><span data-ttu-id="d900c-120">HYPER-V 上运行 BizTalk Server 解决方案时的磁盘性能</span><span class="sxs-lookup"><span data-stu-id="d900c-120">Disk Performance When Running a BizTalk Server Solution on Hyper-V</span></span>  
 <span data-ttu-id="d900c-121">BizTalk Server 是极其数据库密集型应用程序可能需要创建的 SQL Server 中的最多 13 个数据库。</span><span class="sxs-lookup"><span data-stu-id="d900c-121">BizTalk Server is an extremely database intensive application that may require the creation of up to 13 databases in SQL Server.</span></span> <span data-ttu-id="d900c-122">BizTalk Server 将数据保存到磁盘很好的频率和此外，MSDTC 事务的上下文中执行此操作。</span><span class="sxs-lookup"><span data-stu-id="d900c-122">BizTalk Server persists data to disk with great frequency and furthermore, does so within the context of an MSDTC transaction.</span></span> <span data-ttu-id="d900c-123">因此，数据库性能至关重要的任何 BizTalk Server 解决方案的整体性能。</span><span class="sxs-lookup"><span data-stu-id="d900c-123">Therefore, database performance is paramount to the overall performance of any BizTalk Server solution.</span></span> <span data-ttu-id="d900c-124">HYPER-V 提供了综合的 SCSI 控制器和 Virtual Server 2005 提供的 IDE 筛选器驱动程序的这两个通过使用仿真的 IDE 设备，如提供显著的性能优势。</span><span class="sxs-lookup"><span data-stu-id="d900c-124">Hyper-V provides a synthetic SCSI controller and an IDE filter driver which both provide significant performance benefits over using an emulated IDE device such as is provided with Virtual Server 2005.</span></span>  
  
 <span data-ttu-id="d900c-125">配置为使用 SCSI 控制器的数据卷的磁盘。</span><span class="sxs-lookup"><span data-stu-id="d900c-125">Configure disks for data volumes using the SCSI controller.</span></span> <span data-ttu-id="d900c-126">这将保证安装集成服务，因为如果安装 HYPER-V 集成服务，而无需安装 HYPER-V 集成服务中，模拟的 IDE 控制器可用，可以仅安装 SCSI 控制器。</span><span class="sxs-lookup"><span data-stu-id="d900c-126">This will guarantee that the integration services are installed because the SCSI controller can only be installed if Hyper-V integration services are installed whereas the emulated IDE controller is available without installing Hyper-V integration services.</span></span> <span data-ttu-id="d900c-127">使用 SCSI 控制器或使用 integration services 提供的 IDE 筛选器驱动程序执行的磁盘 I/O 是明显优于磁盘 I/O 性能提供与仿真的 IDE 控制器。</span><span class="sxs-lookup"><span data-stu-id="d900c-127">Disk I/O performed using either the SCSI controller or the IDE filter driver provided with integration services is significantly better than disk I/O performance provided with the emulated IDE controller.</span></span> <span data-ttu-id="d900c-128">因此，若要确保获得最佳磁盘 I/O 性能的 HYPER-V 虚拟化环境中的数据文件，主机和来宾操作系统上安装集成服务并将数据卷的磁盘合成 SCSI 控制器的配置。</span><span class="sxs-lookup"><span data-stu-id="d900c-128">Therefore, to ensure optimal disk I/O performance for the data files in a Hyper-V virtualized environment, install integration services on both the host and guest operating system and configure disks for data volumes with the synthetic SCSI controller.</span></span> <span data-ttu-id="d900c-129">对于跨多个数据驱动器的高密集型存储 I/O 工作负荷，每个 VHD 应附加到单独的合成 SCSI 控制器以提高整体性能。</span><span class="sxs-lookup"><span data-stu-id="d900c-129">For highly intensive storage I/O workloads that span multiple data drives, each VHD should be attached to a separate synthetic SCSI controller for better overall performance.</span></span> <span data-ttu-id="d900c-130">此外，每个 VHD 应存储在单独的物理磁盘或 Lun 上。</span><span class="sxs-lookup"><span data-stu-id="d900c-130">In addition, each VHD should be stored on separate physical disks or LUNs.</span></span>  
  
#### <a name="measuring-passthrough-disk-performance"></a><span data-ttu-id="d900c-131">度量传递磁盘性能</span><span class="sxs-lookup"><span data-stu-id="d900c-131">Measuring PassThrough Disk Performance</span></span>  
 <span data-ttu-id="d900c-132">在任何合并练习务必使最充分地利用可用资源。</span><span class="sxs-lookup"><span data-stu-id="d900c-132">During any consolidation exercise it is important to make maximum use of available resources.</span></span> <span data-ttu-id="d900c-133">如前文所述，SQL 数据卷上的存储 I/O 在 BizTalk Server 解决方案的整体性能中扮演的重要部分。</span><span class="sxs-lookup"><span data-stu-id="d900c-133">As discussed previously, storage I/O on SQL data volumes plays a significant part in the overall performance of a BizTalk Server solution.</span></span> <span data-ttu-id="d900c-134">因此，本指南中的 HYPER-V 中的传递磁盘性能的物理磁盘的相对性能进行了测试。</span><span class="sxs-lookup"><span data-stu-id="d900c-134">Therefore as part of this guidance, the relative performance of a physical disk to the performance of a passthrough disk in Hyper-V was tested.</span></span> <span data-ttu-id="d900c-135">MessageBox 数据的相对性能中 Physical_SQL01 的驱动器和 Virtual_SQL01 测量使用的 IOMeter 开放源代码工具最初由 Intel Corporation 和现在维护的开放源开发实验室 (OSDL)。</span><span class="sxs-lookup"><span data-stu-id="d900c-135">The relative performance of the MessageBox data drive in Physical_SQL01 and Virtual_SQL01 was measured using the IOMeter open source tool originally developed by Intel Corporation and now maintained by the open Source Development Lab (OSDL).</span></span> <span data-ttu-id="d900c-136">IOMeter 有关详细信息，请参阅[ http://go.microsoft.com/fwlink/?LinkId=122412 ](http://go.microsoft.com/fwlink/?LinkId=122412)。</span><span class="sxs-lookup"><span data-stu-id="d900c-136">For more information about IOMeter, see [http://go.microsoft.com/fwlink/?LinkId=122412](http://go.microsoft.com/fwlink/?LinkId=122412).</span></span>  
  
 <span data-ttu-id="d900c-137">下表描述了在测试环境、 使用 IOMeter 配置选项、 已运行的测试的说明和结果的摘要中使用的物理和虚拟硬件配置。</span><span class="sxs-lookup"><span data-stu-id="d900c-137">The following tables describe the physical and virtual hardware configuration used in the test environment, the IOMeter configuration options that were used, a description of the test that was run, and a summary of results.</span></span>  
  
#### <a name="configuration-used-for-testing"></a><span data-ttu-id="d900c-138">用于测试的配置</span><span class="sxs-lookup"><span data-stu-id="d900c-138">Configuration Used for Testing</span></span>  
  
### <a name="physicalsql01"></a><span data-ttu-id="d900c-139">Physical_SQL01</span><span class="sxs-lookup"><span data-stu-id="d900c-139">Physical_SQL01</span></span>  
  
|||  
|-|-|  
|<span data-ttu-id="d900c-140">**Model**</span><span class="sxs-lookup"><span data-stu-id="d900c-140">**Model**</span></span>|<span data-ttu-id="d900c-141">HP DL580</span><span class="sxs-lookup"><span data-stu-id="d900c-141">HP DL580</span></span>|  
|<span data-ttu-id="d900c-142">**处理器**</span><span class="sxs-lookup"><span data-stu-id="d900c-142">**Processor**</span></span>|<span data-ttu-id="d900c-143">四核处理器，四核 Intel Xeon 2.4 Ghz</span><span class="sxs-lookup"><span data-stu-id="d900c-143">Quad processor, Quad-core Intel Xeon 2.4Ghz</span></span>|  
|<span data-ttu-id="d900c-144">**内存**</span><span class="sxs-lookup"><span data-stu-id="d900c-144">**Memory**</span></span>|<span data-ttu-id="d900c-145">8 GB</span><span class="sxs-lookup"><span data-stu-id="d900c-145">8 GB</span></span>|  
|<span data-ttu-id="d900c-146">**网络**</span><span class="sxs-lookup"><span data-stu-id="d900c-146">**Networking**</span></span>|<span data-ttu-id="d900c-147">HP NC3T3i 多功能千兆位 Server 适配器</span><span class="sxs-lookup"><span data-stu-id="d900c-147">HP NC3T3i Multifunction Gigabit Server adapter</span></span>|  
|<span data-ttu-id="d900c-148">**SAN 配置**</span><span class="sxs-lookup"><span data-stu-id="d900c-148">**SAN configuration**</span></span>|<span data-ttu-id="d900c-149">直连的 SAN 存储 （请参阅下表）</span><span class="sxs-lookup"><span data-stu-id="d900c-149">Direct attached SAN storage (see table below)</span></span>|  
  
### <a name="physicalsql01--san-configuration"></a><span data-ttu-id="d900c-150">Physical_SQL01 – SAN 配置</span><span class="sxs-lookup"><span data-stu-id="d900c-150">Physical_SQL01 – SAN Configuration</span></span>  
  
|<span data-ttu-id="d900c-151">驱动器号</span><span class="sxs-lookup"><span data-stu-id="d900c-151">Drive letter</span></span>|<span data-ttu-id="d900c-152">Description</span><span class="sxs-lookup"><span data-stu-id="d900c-152">Description</span></span>|<span data-ttu-id="d900c-153">LUN 的大小</span><span class="sxs-lookup"><span data-stu-id="d900c-153">LUN Size</span></span>|<span data-ttu-id="d900c-154">RAID 配置</span><span class="sxs-lookup"><span data-stu-id="d900c-154">RAID configuration</span></span>|  
|------------------|-----------------|--------------|------------------------|  
|<span data-ttu-id="d900c-155">G:</span><span class="sxs-lookup"><span data-stu-id="d900c-155">G:</span></span>|<span data-ttu-id="d900c-156">Data_Sys</span><span class="sxs-lookup"><span data-stu-id="d900c-156">Data_Sys</span></span>|<span data-ttu-id="d900c-157">10</span><span class="sxs-lookup"><span data-stu-id="d900c-157">10</span></span>|<span data-ttu-id="d900c-158">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-158">RAID 0 + 1</span></span>|  
|<span data-ttu-id="d900c-159">H:</span><span class="sxs-lookup"><span data-stu-id="d900c-159">H:</span></span>|<span data-ttu-id="d900c-160">Logs_Sys</span><span class="sxs-lookup"><span data-stu-id="d900c-160">Logs_Sys</span></span>|<span data-ttu-id="d900c-161">10</span><span class="sxs-lookup"><span data-stu-id="d900c-161">10</span></span>|<span data-ttu-id="d900c-162">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-162">RAID 0 + 1</span></span>|  
|<span data-ttu-id="d900c-163">实现：</span><span class="sxs-lookup"><span data-stu-id="d900c-163">I:</span></span>|<span data-ttu-id="d900c-164">Data_TempDb</span><span class="sxs-lookup"><span data-stu-id="d900c-164">Data_TempDb</span></span>|<span data-ttu-id="d900c-165">50</span><span class="sxs-lookup"><span data-stu-id="d900c-165">50</span></span>|<span data-ttu-id="d900c-166">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-166">RAID 0 + 1</span></span>|  
|<span data-ttu-id="d900c-167">J:</span><span class="sxs-lookup"><span data-stu-id="d900c-167">J:</span></span>|<span data-ttu-id="d900c-168">Logs_TempDb</span><span class="sxs-lookup"><span data-stu-id="d900c-168">Logs_TempDb</span></span>|<span data-ttu-id="d900c-169">50</span><span class="sxs-lookup"><span data-stu-id="d900c-169">50</span></span>|<span data-ttu-id="d900c-170">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-170">RAID 0 + 1</span></span>|  
|<span data-ttu-id="d900c-171">K:</span><span class="sxs-lookup"><span data-stu-id="d900c-171">K:</span></span>|<span data-ttu-id="d900c-172">Data_BtsMsgBox</span><span class="sxs-lookup"><span data-stu-id="d900c-172">Data_BtsMsgBox</span></span>|<span data-ttu-id="d900c-173">300</span><span class="sxs-lookup"><span data-stu-id="d900c-173">300</span></span>|<span data-ttu-id="d900c-174">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-174">RAID 0 + 1</span></span>|  
|<span data-ttu-id="d900c-175">L:</span><span class="sxs-lookup"><span data-stu-id="d900c-175">L:</span></span>|<span data-ttu-id="d900c-176">Logs_BtsMsgBox</span><span class="sxs-lookup"><span data-stu-id="d900c-176">Logs_BtsMsgBox</span></span>|<span data-ttu-id="d900c-177">100</span><span class="sxs-lookup"><span data-stu-id="d900c-177">100</span></span>|<span data-ttu-id="d900c-178">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-178">RAID 0 + 1</span></span>|  
|<span data-ttu-id="d900c-179">M:</span><span class="sxs-lookup"><span data-stu-id="d900c-179">M:</span></span>|<span data-ttu-id="d900c-180">MSDTC</span><span class="sxs-lookup"><span data-stu-id="d900c-180">MSDTC</span></span>|<span data-ttu-id="d900c-181">5</span><span class="sxs-lookup"><span data-stu-id="d900c-181">5</span></span>|<span data-ttu-id="d900c-182">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-182">RAID 0 + 1</span></span>|  
  
### <a name="hyper-vhostsql01"></a><span data-ttu-id="d900c-183">Hyper-V_Host_SQL01</span><span class="sxs-lookup"><span data-stu-id="d900c-183">Hyper-V_Host_SQL01</span></span>  
  
|||  
|-|-|  
|<span data-ttu-id="d900c-184">**Model**</span><span class="sxs-lookup"><span data-stu-id="d900c-184">**Model**</span></span>|<span data-ttu-id="d900c-185">HP DL580</span><span class="sxs-lookup"><span data-stu-id="d900c-185">HP DL580</span></span>|  
|<span data-ttu-id="d900c-186">**处理器**</span><span class="sxs-lookup"><span data-stu-id="d900c-186">**Processor**</span></span>|<span data-ttu-id="d900c-187">四核处理器，四核 Intel Xeon 2.4 Ghz</span><span class="sxs-lookup"><span data-stu-id="d900c-187">Quad processor, Quad-core Intel Xeon 2.4Ghz</span></span>|  
|<span data-ttu-id="d900c-188">**内存**</span><span class="sxs-lookup"><span data-stu-id="d900c-188">**Memory**</span></span>|<span data-ttu-id="d900c-189">32 GB</span><span class="sxs-lookup"><span data-stu-id="d900c-189">32 GB</span></span>|  
|<span data-ttu-id="d900c-190">**网络**</span><span class="sxs-lookup"><span data-stu-id="d900c-190">**Networking**</span></span>|<span data-ttu-id="d900c-191">Broadcom BCM5708C NetXtreme II GigEHP DL380 G5</span><span class="sxs-lookup"><span data-stu-id="d900c-191">Broadcom BCM5708C NetXtreme II GigEHP DL380 G5</span></span>|  
  
### <a name="virtualsql01---virtual-machine-configuration"></a><span data-ttu-id="d900c-192">Virtual_SQL01-虚拟机配置</span><span class="sxs-lookup"><span data-stu-id="d900c-192">Virtual_SQL01 - Virtual Machine Configuration</span></span>  
  
|||  
|-|-|  
|<span data-ttu-id="d900c-193">**虚拟处理器**</span><span class="sxs-lookup"><span data-stu-id="d900c-193">**Virtual processors**</span></span>|<span data-ttu-id="d900c-194">分配 4</span><span class="sxs-lookup"><span data-stu-id="d900c-194">4 allocated</span></span>|  
|<span data-ttu-id="d900c-195">**内存**</span><span class="sxs-lookup"><span data-stu-id="d900c-195">**Memory**</span></span>|<span data-ttu-id="d900c-196">8 GB</span><span class="sxs-lookup"><span data-stu-id="d900c-196">8 GB</span></span>|  
|<span data-ttu-id="d900c-197">**网络**</span><span class="sxs-lookup"><span data-stu-id="d900c-197">**Networking**</span></span>|<span data-ttu-id="d900c-198">虚拟机的网络连接到：</span><span class="sxs-lookup"><span data-stu-id="d900c-198">Virtual Machine Networking connected to:</span></span><br /><span data-ttu-id="d900c-199">Broadcom BCM5708C NetXtreme II GigE</span><span class="sxs-lookup"><span data-stu-id="d900c-199">Broadcom BCM5708C NetXtreme II GigE</span></span>|  
|<span data-ttu-id="d900c-200">**硬盘配置**</span><span class="sxs-lookup"><span data-stu-id="d900c-200">**Hard disk configuration**</span></span>|<span data-ttu-id="d900c-201">**IDE 控制器**– 30 GB 的操作系统为固定 vhd</span><span class="sxs-lookup"><span data-stu-id="d900c-201">**IDE controller** – 30 GB fixed vhd for Operating System</span></span><br /><span data-ttu-id="d900c-202">**SCSI 控制器**-7 直接连接 （请参阅下表） 的传递 SAN Lun</span><span class="sxs-lookup"><span data-stu-id="d900c-202">**SCSI controller** - 7 directly attached passthrough SAN LUNs (see table below)</span></span>|  
  
### <a name="virtualsql01--san-configuration"></a><span data-ttu-id="d900c-203">Virtual_SQL01 – SAN 配置</span><span class="sxs-lookup"><span data-stu-id="d900c-203">Virtual_SQL01 – SAN Configuration</span></span>  
  
|<span data-ttu-id="d900c-204">驱动器号</span><span class="sxs-lookup"><span data-stu-id="d900c-204">Drive letter</span></span>|<span data-ttu-id="d900c-205">Description</span><span class="sxs-lookup"><span data-stu-id="d900c-205">Description</span></span>|<span data-ttu-id="d900c-206">LUN 的大小</span><span class="sxs-lookup"><span data-stu-id="d900c-206">LUN Size</span></span>|<span data-ttu-id="d900c-207">RAID 配置</span><span class="sxs-lookup"><span data-stu-id="d900c-207">RAID configuration</span></span>|  
|------------------|-----------------|--------------|------------------------|  
|<span data-ttu-id="d900c-208">G:</span><span class="sxs-lookup"><span data-stu-id="d900c-208">G:</span></span>|<span data-ttu-id="d900c-209">Data_Sys</span><span class="sxs-lookup"><span data-stu-id="d900c-209">Data_Sys</span></span>|<span data-ttu-id="d900c-210">10</span><span class="sxs-lookup"><span data-stu-id="d900c-210">10</span></span>|<span data-ttu-id="d900c-211">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-211">RAID 0 + 1</span></span>|  
|<span data-ttu-id="d900c-212">H:</span><span class="sxs-lookup"><span data-stu-id="d900c-212">H:</span></span>|<span data-ttu-id="d900c-213">Logs_Sys</span><span class="sxs-lookup"><span data-stu-id="d900c-213">Logs_Sys</span></span>|<span data-ttu-id="d900c-214">10</span><span class="sxs-lookup"><span data-stu-id="d900c-214">10</span></span>|<span data-ttu-id="d900c-215">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-215">RAID 0 + 1</span></span>|  
|<span data-ttu-id="d900c-216">实现：</span><span class="sxs-lookup"><span data-stu-id="d900c-216">I:</span></span>|<span data-ttu-id="d900c-217">Data_TempDb</span><span class="sxs-lookup"><span data-stu-id="d900c-217">Data_TempDb</span></span>|<span data-ttu-id="d900c-218">50</span><span class="sxs-lookup"><span data-stu-id="d900c-218">50</span></span>|<span data-ttu-id="d900c-219">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-219">RAID 0 + 1</span></span>|  
|<span data-ttu-id="d900c-220">J:</span><span class="sxs-lookup"><span data-stu-id="d900c-220">J:</span></span>|<span data-ttu-id="d900c-221">Logs_TempDb</span><span class="sxs-lookup"><span data-stu-id="d900c-221">Logs_TempDb</span></span>|<span data-ttu-id="d900c-222">50</span><span class="sxs-lookup"><span data-stu-id="d900c-222">50</span></span>|<span data-ttu-id="d900c-223">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-223">RAID 0 + 1</span></span>|  
|<span data-ttu-id="d900c-224">K:</span><span class="sxs-lookup"><span data-stu-id="d900c-224">K:</span></span>|<span data-ttu-id="d900c-225">Data_BtsMsgBox</span><span class="sxs-lookup"><span data-stu-id="d900c-225">Data_BtsMsgBox</span></span>|<span data-ttu-id="d900c-226">300</span><span class="sxs-lookup"><span data-stu-id="d900c-226">300</span></span>|<span data-ttu-id="d900c-227">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-227">RAID 0 + 1</span></span>|  
|<span data-ttu-id="d900c-228">L:</span><span class="sxs-lookup"><span data-stu-id="d900c-228">L:</span></span>|<span data-ttu-id="d900c-229">Logs_BtsMsgBox</span><span class="sxs-lookup"><span data-stu-id="d900c-229">Logs_BtsMsgBox</span></span>|<span data-ttu-id="d900c-230">100</span><span class="sxs-lookup"><span data-stu-id="d900c-230">100</span></span>|<span data-ttu-id="d900c-231">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-231">RAID 0 + 1</span></span>|  
|<span data-ttu-id="d900c-232">M:</span><span class="sxs-lookup"><span data-stu-id="d900c-232">M:</span></span>|<span data-ttu-id="d900c-233">MSDTC</span><span class="sxs-lookup"><span data-stu-id="d900c-233">MSDTC</span></span>|<span data-ttu-id="d900c-234">5</span><span class="sxs-lookup"><span data-stu-id="d900c-234">5</span></span>|<span data-ttu-id="d900c-235">RAID 0 + 1</span><span class="sxs-lookup"><span data-stu-id="d900c-235">RAID 0 + 1</span></span>|  
  
#### <a name="iometer-configuration"></a><span data-ttu-id="d900c-236">IOMeter 配置</span><span class="sxs-lookup"><span data-stu-id="d900c-236">IOMeter Configuration</span></span>  
 <span data-ttu-id="d900c-237">IOMeter 工具可以用作基准和故障排除工具通过复制应用程序的读/写性能。</span><span class="sxs-lookup"><span data-stu-id="d900c-237">The IOMeter tool can be used as a benchmark and troubleshooting tool by replicating the read/write performance of applications.</span></span> <span data-ttu-id="d900c-238">IOMeter 是性能的一个可配置的工具，可用于模拟许多不同类型。</span><span class="sxs-lookup"><span data-stu-id="d900c-238">IOMeter is a configurable tool that can be used to simulate many different types of performance.</span></span> <span data-ttu-id="d900c-239">对于此测试方案，IOMeter 配置参数已设置为在下表描述这两个物理[!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)]进行了测试的计算机和运行来宾操作系统上[!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)]中的 HYPER-V 虚拟机:</span><span class="sxs-lookup"><span data-stu-id="d900c-239">For purposes of this test scenario, IOMeter configuration parameters were set as described in the table below on both the physical [!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)] computer that was tested and on the guest operating system that was running [!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)] in a Hyper-V virtual machine:</span></span>  
  
### <a name="iometer--passthrough-disk-comparison-test-configuration"></a><span data-ttu-id="d900c-240">IOMeter – 传递磁盘比较测试配置</span><span class="sxs-lookup"><span data-stu-id="d900c-240">IOMeter – Passthrough Disk Comparison Test Configuration</span></span>  
  
|                             |                     |
|-----------------------------|---------------------|
|       <span data-ttu-id="d900c-241">**测试长度**</span><span class="sxs-lookup"><span data-stu-id="d900c-241">**Test length**</span></span>       |     <span data-ttu-id="d900c-242">10 分钟。</span><span class="sxs-lookup"><span data-stu-id="d900c-242">10 minutes</span></span>      |
|      <span data-ttu-id="d900c-243">**技能强化时间**</span><span class="sxs-lookup"><span data-stu-id="d900c-243">**Ramp up time**</span></span>       |     <span data-ttu-id="d900c-244">30 秒</span><span class="sxs-lookup"><span data-stu-id="d900c-244">30 seconds</span></span>      |
|    <span data-ttu-id="d900c-245">**工作线程数**</span><span class="sxs-lookup"><span data-stu-id="d900c-245">**Number of workers**</span></span>    |          <span data-ttu-id="d900c-246">4</span><span class="sxs-lookup"><span data-stu-id="d900c-246">4</span></span>          |
|  <span data-ttu-id="d900c-247">**传输请求大小**</span><span class="sxs-lookup"><span data-stu-id="d900c-247">**Transfer request size**</span></span>  |        <span data-ttu-id="d900c-248">2 KB</span><span class="sxs-lookup"><span data-stu-id="d900c-248">2 KB</span></span>         |
| <span data-ttu-id="d900c-249">**读/写分发**</span><span class="sxs-lookup"><span data-stu-id="d900c-249">**Read/write distribution**</span></span> | <span data-ttu-id="d900c-250">66%的读取，33%写入</span><span class="sxs-lookup"><span data-stu-id="d900c-250">66% read, 33% write</span></span> |
|      <span data-ttu-id="d900c-251">**突发长度**</span><span class="sxs-lookup"><span data-stu-id="d900c-251">**Burst length**</span></span>       |       <span data-ttu-id="d900c-252">1 I/o</span><span class="sxs-lookup"><span data-stu-id="d900c-252">1 I/Os</span></span>        |
|      <span data-ttu-id="d900c-253">**目标驱动器**</span><span class="sxs-lookup"><span data-stu-id="d900c-253">**Target Drive**</span></span>       |         <span data-ttu-id="d900c-254">K:\\</span><span class="sxs-lookup"><span data-stu-id="d900c-254">K:\\</span></span>         |
  
#### <a name="test-description"></a><span data-ttu-id="d900c-255">测试说明</span><span class="sxs-lookup"><span data-stu-id="d900c-255">Test Description</span></span>  
 <span data-ttu-id="d900c-256">[!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)]服务已停止两个服务器以确保 IOMeter 是对磁盘执行 I/O 的唯一进程上。</span><span class="sxs-lookup"><span data-stu-id="d900c-256">The [!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)] service was stopped on both servers to ensure that IOMeter was the only process performing I/O against the disk.</span></span> <span data-ttu-id="d900c-257">使用 LUN 的此测试中都位于同一个 SAN 这专用于此实验室环境上。</span><span class="sxs-lookup"><span data-stu-id="d900c-257">The LUN’s used in this test were both located on the same SAN which was dedicated to this lab environment.</span></span> <span data-ttu-id="d900c-258">针对 SAN 上测试以确保结果不倾斜期间不执行任何其他 I/O 活动。</span><span class="sxs-lookup"><span data-stu-id="d900c-258">No other I/O activity was performed against the SAN during the test to ensure that the results were not skewed.</span></span> <span data-ttu-id="d900c-259">然后通过从每个本地执行 IOMeter 工具运行测试时[!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)]和收集以下性能监视器计数器：</span><span class="sxs-lookup"><span data-stu-id="d900c-259">The test was then run by executing the IOMeter tool locally from each [!INCLUDE[btsSQLServerNoVersion](../includes/btssqlservernoversion-md.md)] and the following performance monitor counters were collected:</span></span>  
  
 <span data-ttu-id="d900c-260">**收集从 Virtual_SQL01 和 Physical_SQL01**:</span><span class="sxs-lookup"><span data-stu-id="d900c-260">**Collected from both Virtual_SQL01 and Physical_SQL01**:</span></span>  
  
- <span data-ttu-id="d900c-261">\LogicalDisk (\*)\\\*</span><span class="sxs-lookup"><span data-stu-id="d900c-261">\LogicalDisk(\*)\\\*</span></span>  
  
- <span data-ttu-id="d900c-262">\PhysicalDisk (\*)\\\*</span><span class="sxs-lookup"><span data-stu-id="d900c-262">\PhysicalDisk(\*)\\\*</span></span>  
  
  <span data-ttu-id="d900c-263">**收集从虚拟机超 V_02**:</span><span class="sxs-lookup"><span data-stu-id="d900c-263">**Collected from virtual machine Hyper-V_02**:</span></span>  
  
- <span data-ttu-id="d900c-264">\\Hyper V 虚拟存储设备\\\*</span><span class="sxs-lookup"><span data-stu-id="d900c-264">\\Hyper-V Virtual Storage Device\\\*</span></span>  
  
### <a name="results"></a><span data-ttu-id="d900c-265">结果</span><span class="sxs-lookup"><span data-stu-id="d900c-265">Results</span></span>  
 <span data-ttu-id="d900c-266">传递磁盘是吞吐量的可以重复使用超过 90%的直接连接到 Physical_SQL01 SAN LUN。</span><span class="sxs-lookup"><span data-stu-id="d900c-266">The passthrough disk was able to attain over 90% of the throughput of the SAN LUN connected directly to Physical_SQL01.</span></span>  <span data-ttu-id="d900c-267">总、 读取和写入相同的每秒传输的总 MB 每秒 I/o 是所有都在 10%。</span><span class="sxs-lookup"><span data-stu-id="d900c-267">Total, read and write I/Os per second were all within 10% as was the total MB transferred per second.</span></span>  <span data-ttu-id="d900c-268">对于正常磁盘响应时间应介于 1-15 毫秒的读取和写入。</span><span class="sxs-lookup"><span data-stu-id="d900c-268">Response times for healthy disks should be between 1-15 ms for read and write.</span></span> <span data-ttu-id="d900c-269">平均 I/O 响应时间是小于 4 毫秒，这两个磁盘上。</span><span class="sxs-lookup"><span data-stu-id="d900c-269">Average I/O response times were less than 4 ms on both disks.</span></span> <span data-ttu-id="d900c-270">随机读取响应时间为 5.4 毫秒在物理上和 5.7 ms 传递磁盘上。</span><span class="sxs-lookup"><span data-stu-id="d900c-270">Random reads response time was 5.4 ms on the physical and 5.7 ms on the pass-through disk.</span></span> <span data-ttu-id="d900c-271">写入响应时间为小于 0.5 毫秒的物理和虚拟环境。</span><span class="sxs-lookup"><span data-stu-id="d900c-271">Write response time was less than 0.5 ms on both the physical and virtual environments.</span></span>  
  
 <span data-ttu-id="d900c-272">结果表明使用已启用的 SCSI 控制器的传递磁盘，可以提供超过 90%的直接连接的物理磁盘的性能。</span><span class="sxs-lookup"><span data-stu-id="d900c-272">The results indicate that a passthrough disk using the enlightened SCSI controller can provide over 90% of the performance of a directly connected physical disk.</span></span> <span data-ttu-id="d900c-273">I/O 子系统的性能至关重要的有效的 BizTalk Server 操作，通过提供出色的吞吐量和响应时间的 HYPER-V 适用的最佳候选项合并 BizTalk Server 环境。</span><span class="sxs-lookup"><span data-stu-id="d900c-273">I/O subsystem performance is critical for efficient BizTalk Server operation, by providing excellent throughput and response times Hyper-V is an excellent candidate for consolidating a BizTalk Server environment.</span></span> <span data-ttu-id="d900c-274">下表提供了比较的传递磁盘的物理磁盘性能时，观察到的磁盘测试结果摘要：</span><span class="sxs-lookup"><span data-stu-id="d900c-274">The table below provides a summary of the disk test results observed when comparing performance of a passthrough disk to a physical disk:</span></span>  
  
|<span data-ttu-id="d900c-275">度量值</span><span class="sxs-lookup"><span data-stu-id="d900c-275">Measurement</span></span>|<span data-ttu-id="d900c-276">Physical_SQL01 （物理磁盘）</span><span class="sxs-lookup"><span data-stu-id="d900c-276">Physical_SQL01 (Physical Disk)</span></span>|<span data-ttu-id="d900c-277">Virtual_SQL01 （直通）</span><span class="sxs-lookup"><span data-stu-id="d900c-277">Virtual_SQL01 (passthrough)</span></span>|<span data-ttu-id="d900c-278">为物理磁盘的传递磁盘的相对性能</span><span class="sxs-lookup"><span data-stu-id="d900c-278">Relative performance of passthrough disks to physical disks</span></span>|  
|-----------------|---------------------------------------|------------------------------------|-----------------------------------------------------------------|  
|<span data-ttu-id="d900c-279">每秒的总 i/o 数</span><span class="sxs-lookup"><span data-stu-id="d900c-279">Total I/Os per second</span></span>|<span data-ttu-id="d900c-280">269.73</span><span class="sxs-lookup"><span data-stu-id="d900c-280">269.73</span></span>|<span data-ttu-id="d900c-281">250.47</span><span class="sxs-lookup"><span data-stu-id="d900c-281">250.47</span></span>|<span data-ttu-id="d900c-282">92.86%</span><span class="sxs-lookup"><span data-stu-id="d900c-282">92.86%</span></span>|  
|<span data-ttu-id="d900c-283">每秒读取 i/o 数</span><span class="sxs-lookup"><span data-stu-id="d900c-283">Read I/Os per second</span></span>|<span data-ttu-id="d900c-284">180.73</span><span class="sxs-lookup"><span data-stu-id="d900c-284">180.73</span></span>|<span data-ttu-id="d900c-285">167.60</span><span class="sxs-lookup"><span data-stu-id="d900c-285">167.60</span></span>|<span data-ttu-id="d900c-286">92.74%</span><span class="sxs-lookup"><span data-stu-id="d900c-286">92.74%</span></span>|  
|<span data-ttu-id="d900c-287">每秒写入 I/o</span><span class="sxs-lookup"><span data-stu-id="d900c-287">Write I/Os per second</span></span>|<span data-ttu-id="d900c-288">89.00</span><span class="sxs-lookup"><span data-stu-id="d900c-288">89.00</span></span>|<span data-ttu-id="d900c-289">82.87</span><span class="sxs-lookup"><span data-stu-id="d900c-289">82.87</span></span>|<span data-ttu-id="d900c-290">93.11%</span><span class="sxs-lookup"><span data-stu-id="d900c-290">93.11%</span></span>|  
|<span data-ttu-id="d900c-291">总 Mb / 秒</span><span class="sxs-lookup"><span data-stu-id="d900c-291">Total MBs per second</span></span>|<span data-ttu-id="d900c-292">0.53</span><span class="sxs-lookup"><span data-stu-id="d900c-292">0.53</span></span>|<span data-ttu-id="d900c-293">0.49</span><span class="sxs-lookup"><span data-stu-id="d900c-293">0.49</span></span>|<span data-ttu-id="d900c-294">92.45%</span><span class="sxs-lookup"><span data-stu-id="d900c-294">92.45%</span></span>|  
|<span data-ttu-id="d900c-295">平均读取响应时间 （毫秒）</span><span class="sxs-lookup"><span data-stu-id="d900c-295">Average read response time (ms)</span></span>|<span data-ttu-id="d900c-296">5.4066</span><span class="sxs-lookup"><span data-stu-id="d900c-296">5.4066</span></span>|<span data-ttu-id="d900c-297">5.7797</span><span class="sxs-lookup"><span data-stu-id="d900c-297">5.7797</span></span>|<span data-ttu-id="d900c-298">93.54%</span><span class="sxs-lookup"><span data-stu-id="d900c-298">93.54%</span></span>|  
|<span data-ttu-id="d900c-299">平均写入响应时间 （毫秒）</span><span class="sxs-lookup"><span data-stu-id="d900c-299">Average write response time (ms)</span></span>|<span data-ttu-id="d900c-300">0.2544</span><span class="sxs-lookup"><span data-stu-id="d900c-300">0.2544</span></span>|<span data-ttu-id="d900c-301">0.3716</span><span class="sxs-lookup"><span data-stu-id="d900c-301">0.3716</span></span>|<span data-ttu-id="d900c-302">68.42%**注意：** 虽然的传递磁盘平均写入响应时间的相对性能 68.42%的物理磁盘的性能，但仍也在已传递磁盘的平均写入响应时间建立可接受的限制为 10 毫秒。</span><span class="sxs-lookup"><span data-stu-id="d900c-302">68.42% **Note:**  Although the relative performance of the pass through disks for Average write response time was 68.42% of the performance of physical disks, the Average write response time of the passthrough disks was still well within established acceptable limits of 10 ms.</span></span>|  
|<span data-ttu-id="d900c-303">平均 I/O 响应时间 （毫秒）</span><span class="sxs-lookup"><span data-stu-id="d900c-303">Average I/O response time (ms)</span></span>|<span data-ttu-id="d900c-304">3.7066</span><span class="sxs-lookup"><span data-stu-id="d900c-304">3.7066</span></span>|<span data-ttu-id="d900c-305">3.9904</span><span class="sxs-lookup"><span data-stu-id="d900c-305">3.9904</span></span>|<span data-ttu-id="d900c-306">93.89%</span><span class="sxs-lookup"><span data-stu-id="d900c-306">93.89%</span></span>|  
  
> [!NOTE]  
>  <span data-ttu-id="d900c-307">通过将传递磁盘的相应物理磁盘值的值来计算每秒的总 i/o 数、 每秒读取 i/o 数、 每秒写入 I/o 和总 Mb / 秒的百分比值。</span><span class="sxs-lookup"><span data-stu-id="d900c-307">The percentage values for Total I/Os per second, Read I/Os per second, Write I/Os per second, and Total MBs per second were calculated by dividing passthrough disk values by the corresponding physical disk values.</span></span>  
>   
>  <span data-ttu-id="d900c-308">平均值的百分比值读取响应时间 （毫秒），平均写入响应时间 （毫秒），并通过将物理磁盘对值进行相应的传递磁盘值来计算平均 I/O 响应时间 （毫秒）。</span><span class="sxs-lookup"><span data-stu-id="d900c-308">The percentage values for Average read response time (ms), Average write response time (ms), and Average I/O response time (ms) were calculated by dividing physical disk values by the corresponding passthrough disk values.</span></span>